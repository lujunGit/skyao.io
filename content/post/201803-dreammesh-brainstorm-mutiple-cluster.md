+++
title = "DreamMesh抛砖引玉(10)-多集群"

date = 2018-04-12
lastmod = 2018-04-12
draft = false

tags = ["DreamMesh"]
summary = "如果有多集群/多机房的支持需求，该如何解决？这个问题和前面列出的service mesh体系和非service mesh的并存问题，可能叠加：如何在多集群/多机房要求下实现service mesh体系和非service mesh的并存。"
abstract = "如果有多集群/多机房的支持需求，该如何解决？这个问题和前面列出的service mesh体系和非service mesh的并存问题，可能叠加：如何在多集群/多机房要求下实现service mesh体系和非service mesh的并存。"

[header]
image = "headers/dreammesh-brainstorm-10.jpg"
caption = ""

+++

如果有多集群/多机房的支持需求，该如何解决？

这个问题和前面列出的service mesh体系和非service mesh的并存问题，可能叠加：如何在多集群/多机房要求下实现service mesh体系和非service mesh的并存。

## 需求

首先看看需求来自哪里：

1. Service Mesh体系和非Service Mesh体系并存/过渡的需要

	见前文 [DreamMesh抛砖引玉(3)-艰难的过渡](../201802-dreammesh-brainstorm-transition/)

2. 多机房部署

	- 有些是考虑容灾，异地双活以备不时之需
	- 大多数没有这么高要求，只是地域差异，应用部署在不同地域
	- 有些是部门/组织/系统不同，各自部署独立系统

3. 技术栈差异

	不同时期使用的技术栈不同，可能造成有多套集群，比如原有dubbo，现在要转向spring cloud，这样在过渡期间会有两套系统。前面列的第一条可以视为是本条的特例。

	如果公司较大，也会出现不同组织采用不同的技术栈导致出现多个集群。

4. 测试运维需要

	可能希望在生产环境之外搭建stagging，test等集群，通常是独立运作，但是偶尔会有想法，希望开个口子以便打通若干个服务或者某个实例，来做测试和验证。

## 场景

我们要打通的多个微服务集群，情况很复杂，可能是以下多种场景混杂：

1. 集群可能是Service Mesh体系和非Service Mesh体系

	- 如果是Service Mesh，可能是Istio/Conduit
	- 如果是非Service Mesh体系，可能是SpringCloud/Dubbo/Motan等

1. 集群可能有不同的部署方式

	- 不同地域
    - 不同机房
    - 网络不同，可能在虚拟网络中如k8s

1. 集群可能使用不同的技术栈，包括：

	- 服务注册机制
	- 远程通讯机制

1. 集群可能用于不同的产品部署阶段

	- prod
	- stagging
	- test

## 难点

需求告诉我们：这个事情有做的价值；而场景则提醒我们：这个事情不简单。

我们来罗列一下实现中的难点所在：

### 服务注册与服务发现

要调用服务，自然需要知道服务在哪里，这涉及到服务注册与服务发现。本集群内只需要知道目标服务实例的ip地址和端口即可，而要跨集群调用服务，事情要变的复杂的多：

* 目标服务在哪个集群？

	答案可能有多种：

	1. 只在本地集群：这是最基本的场景，同集群内服务调用
	2. 只在一个远程集群：这是最简单的跨集群服务调用
	3. 在多个远程集群：服务部署于多个集群，要跨多个集群调用
	4. 在当前集群+远程集群：混合型，最复杂的场景

* 单服务多集群的部署的动机

	什么情况下会需要在多个集群中部署同一个服务的实例，我们来看一下这对服务发现会有何影响。

	* 无状态+性能优化+热备

		最简单的场景：服务无状态，访问的服务实例在本地集群还是远程集群业务处理上无差异。因此，为了保证性能，避免跨集群访问的网络开销，采用每集群各自本地部署服务实例，然后开启诸如"就近访问"/"同机房优先"之类的优化配置。本地实例可用就访问本地实例以优化性能，万一本地实例都不可用，也可以通过调用远程集群的服务实例，以牺牲网络性能为代价实现高可用，相当于将远程集群的服务实例当成热备在用。

		这个场景下，服务发现机制实现起来不复杂：只要简单判断一下本地机房是否还有可用服务实例即可。但是在具体实现上，需要服务注册时标记好机房信息（一般字段为zone），然后在服务发现时提供客户端所在机房的信息，简单比对和过滤即可。

	* 有状态+只读+热备

		当服务有状态时，事情要复杂的多，不过复杂度落在如何保证多机房的状态同步（这是另外一个话题，跨机房数据实时同步）。对于服务注册和服务发现，没有影响。

		只是有状态的情况下，访问本地集群会有更好的数据一致性。而访问远程集群，尤其在切换的瞬间，会有远程数据未及时同步造成访问过时数据的风险。

		因此在决定切换到远程集群的决策上，需要特别谨慎。最恶劣的情况，某个客户端的网络出现问题，无法访问本集群的服务实例，导致做出判断决定切换到远程集群。但是其他客户端还在继续访问本地集群，这样行为就不一致了。

	* 有状态+读写+热备（异地多活）

		但是如果涉及到写操作，则切换到远程集群又涉及到如何同步回本机房的问题。最恶劣的情况，某个客户端的网络出现问题，无法访问本集群的服务实例，导致做出判断决定切换到远程集群，此时本地集群和远程集群都提交写操作，数据如何同步和解决数据冲突就会很棘手。

		这种场景下，切换集群是一个非常严肃的话题，和第一个场景完全不同。

* 服务集群切换的判断机制

    因此，如果做出切换集群的判断，理论上我们有多种选择方式：

    1. 客户端各自判断：只要客户端发现自己得到的本地集群服务实例都不可用，就自行切换到远程集群。这个在实现上是最简单。

    2. 客户端集体判断：需要所有或者多个客户端都判断本地集群服务实例不可用，通过某个协同机制达成一致"某服务本地实例都不可用"，然后同步到本地机房的所有该服务的客户端，再集体切换到远程。此时的好处是实现了"集体行动"，但是，过程复杂实现繁琐。而且在判断不可用到完成协同之间这段时间，客户端即无法访问本地实例也不能切换到远程，只能等待或者报错。

    3. 人工干预：当某个服务切换集群严肃到不能由程序自行判断时，就需要进行人工干预和手动切换。

	从实现上，客户端自行判断，实现简单，也能满足大多数场景的需求，通常做到这一步即可。后面两种判断，需要视实际需求而定。

* 是否需要维持目标服务实例的详细列表

	在本地集群中作服务发现，自然而然的需要拿到和维持目标服务的实例列表。但是，如果目标服务部署于远程集群，则事情又变的复杂了：

	1. 远程集群的网络地址可能不能直接访问

		* 安全和管理考虑，不直接暴露
		* IP地址可能是内网IP或者虚拟IP

	2. 有效的实时同步

		为了维持实例列表的有效性，就必须做到变动的实时监听。跨了集群之后这个操作的成本会大很多，需要将服务注册的监听机制扩展到其他集群。这又把事情搞复杂了。

### SDK必须有能力转发跨集群的请求


### 服务治理必须跨集群通用


## 讨论和反馈

TBD：等收集后整理更新

## 后记

有兴趣的朋友，请联系我的微信，加入DreamMesh内部讨论群。
